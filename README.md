# ðŸ’¥ABSTRACT :

* While conventional song recommendation systems rely on learning user preferences over time, such as past song choices and listening habits, we introduce a novel method in this study. Here, we propose a song recommendation approach where a person's mood is inferred from their picture, and song recommendations are generated based on the predicted mood.

# ðŸ’¥DESCRIPTION :

* Initially, we process the user's image input using the 'OpenCV' Python library for Computer Vision. Subsequently, this processed image is fed into a Convolutional Neural Network (CNN) coupled with a Deep Neural Network (DNN) to predict whether the user's current mood is categorized as 'Happy' or 'Sad'.
* The subsequent step involves employing Unsupervised Machine Learning techniques for song clustering. Utilizing the widely-used K-means algorithm, songs are clustered into two classes: 'VERY ENTERTAINING' (class 0) and 'RELAXED' (class 1). Recommendations are then prioritized based on the current popularity of the respective songs.
* Our approach to song recommendation distinguishes itself by tailoring recommendations to match the user's mood uniquely. For instance, unlike platforms suggesting sad songs when a person feels down, we suggest songs that uplift them ('VERY ENTERTAINING') when sad, and 'RELAXING' songs when they're 'HAPPY'.
* The code for training the neural network is available in the 'Emotion_detector_version2' iPython notebook. Users can modify the network according to their specific requirements or make adjustments to the code provided. The trained model is saved as 'final_model.h5'.

# ðŸ’¥DATA :

* The dataset comprises over 160,000 songs sourced from the Spotify Web API. Additionally, the data section includes categorization by artist, year, or genre.
* Features like acousticness, energy, loudness, and danceability contribute to the effectiveness of the clustering algorithm.

# ðŸ’¥LIBRARIES USED :

* OpenCV
* Tensorflow and Keras
* Scikit-learn
* LightGBM
* Spotipy
* Tkinter
* Pillow

# ðŸ’¥HOW TO USE :

* Launch the application by executing the 'run.py' file, which opens a GUI prompting the user to enter the artist's name.
* The application retrieves necessary albums from the API and initiates the webcam.
* Press the 'q' key to halt image capture, then follow the prompts in the GUI.
* Recommendations are generated by clicking the 'print' button.
   



